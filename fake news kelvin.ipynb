{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.7.3 64-bit ('base': conda)",
      "language": "python",
      "name": "python37364bitbaseconda5f4ca4d05ec0428e858f0d437d648272"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "fake news kelvin.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDcAbRe8h3VA",
        "colab_type": "text"
      },
      "source": [
        "## Use the right version of Tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g9y3nZOiv4p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRyVUBXlh4ms",
        "colab_type": "text"
      },
      "source": [
        "## Call the important statements\n",
        "\n",
        "The following code imports the necessary code to run the code in the rest of this Colaboratory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMBKDMsHiIcp",
        "colab_type": "code",
        "cellView": "form",
        "outputId": "618c0f45-9cbd-4150-adef-db0c8f570101",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 93
        }
      },
      "source": [
        "#@title Call the import statements\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import nltk\n",
        "import re\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import LancasterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "from keras import utils\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import  Dense, Activation, Dropout,Bidirectional, GlobalMaxPool1D,BatchNormalization, Embedding,LSTM, Flatten\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IchjbzTDhhwx",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Load Stopwords, Stemmer, and Lemmatizer\n",
        "\n",
        "sw = stopwords.words('english')\n",
        "stemmer = LancasterStemmer()\n",
        "lemmatizer = WordNetLemmatizer() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMK4CXGN2B47",
        "colab_type": "text"
      },
      "source": [
        "## define the replace_puncts, strip_chars, and puncts\n",
        "\n",
        "this list and arrays are going to be used in defining the functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sB5Lxe7xzkfF",
        "colab": {}
      },
      "source": [
        "replace_puncts = {'`': \"'\", '′': \"'\", '“':'\"', '”': '\"', '‘': \"'\"}\n",
        "\n",
        "strip_chars = [',', '.', '\"', ':', ')', '(', '-', '|', ';', \"'\", '[', ']', '>', '=', '+', '\\\\', '•',  '~', '@', \n",
        " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
        "\n",
        "puncts = ['!', '?', '$', '&', '/', '%', '#', '*','£']\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBQ2Bz3EyeIp",
        "colab_type": "text"
      },
      "source": [
        "## Define functions that clean, lemmatize, process text, and remove stem words from text\n",
        "\n",
        "The following code defines three functions:\n",
        "\n",
        "  * `clean_text`, which convert word to lower case and replace some characters\n",
        "  * `stem`, steam each word in the given text\n",
        "  * `lemm`, which will lemmatize word\n",
        "  * `stopwords1`, which remove the stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVGKYGnGzaBu",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "source": [
        "#@title Define functions that stem, lemmatize, process text, and remove stem words\n",
        "\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    x = x.lower()\n",
        "    x = re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]\\.[^\\s]{2,})\", \"url\", x)\n",
        "    for k, v in replace_puncts.items():\n",
        "        x = x.replace(k, f' {v} ')\n",
        "        \n",
        "    for punct in strip_chars:\n",
        "        x = x.replace(punct, ' ') \n",
        "    \n",
        "    for punct in puncts:\n",
        "        x = x.replace(punct, f' {punct} ')\n",
        "        \n",
        "    x = x.replace(\" '\", \" \")\n",
        "    x = x.replace(\"' \", \" \")\n",
        "   \n",
        "    return x\n",
        "\n",
        "def stopwords1(text):\n",
        "    '''a function for removing the stopword'''\n",
        "    # removing the stop words and lowercasing the selected words\n",
        "    text = [word.lower() for word in text.split() if word.lower() not in sw]\n",
        "    # joining the list of words with space separator\n",
        "    return \" \".join(text)\n",
        "\n",
        "\n",
        "def stemming(text):    \n",
        "    '''a function which stems each word in the given text'''\n",
        "    text = [stemmer.stem(word) for word in text.split()]\n",
        "    return \" \".join(text) \n",
        "\n",
        "def lemm(text):    \n",
        "    text = [lemmatizer.lemmatize(word) for word in text.split()]\n",
        "    return \" \".join(text) \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVvL9S0n4NdU",
        "colab_type": "text"
      },
      "source": [
        "## define text_processing function\n",
        "\n",
        "this `text_processing(text)` function incorporate all the function above into one function that will be used to process `text` later"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0QJQ5vO4LFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_processing(X):\n",
        "    X=X.apply(stopwords1)\n",
        "    X=X.apply(clean_text)\n",
        "    X=X.apply(stemming)\n",
        "    X=X.apply(lemm)\n",
        "    return X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARVujl9YhvrM",
        "colab_type": "text"
      },
      "source": [
        "## Loading Dataset\n",
        "\n",
        "in this project, we use data from Kaggle :  [Fake and Real News Dasaset](https://www.kaggle.com/clmentbisaillon/fake-and-real-news-dataset) \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mB8z8bK5hhw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fake_dataset_url = 'https://raw.githubusercontent.com/Bangkit-2-Jakarta-Team/Fake-News-Detection/master/Datasets/Fake.csv'\n",
        "true_dataset_url='https://raw.githubusercontent.com/Bangkit-2-Jakarta-Team/Fake-News-Detection/master/Datasets/True.csv'\n",
        "\n",
        "df_fake = pd.read_csv(fake_dataset_url)\n",
        "df_true = pd.read_csv(true_dataset_url)\n",
        "df_fake['is_true'] = 0\n",
        "df_true['is_true'] = 1\n",
        "\n",
        "#fake_title = df_fake['title']\n",
        "true_title = df_true['title']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njJg5dTHhhw4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = pd.concat([df_fake,df_true])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD80SUXZhhw9",
        "colab_type": "code",
        "outputId": "62bfff1d-3de3-48a3-dc95-0800ee6d6346",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df_data.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>is_true</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13352</th>\n",
              "      <td>CLINT EASTWOOD Gets Real With The “P*ssy Gener...</td>\n",
              "      <td>Scott and Clint Eastwood are a great father/so...</td>\n",
              "      <td>politics</td>\n",
              "      <td>Aug 3, 2016</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9365</th>\n",
              "      <td>Clinton says she understands U.S. voter concer...</td>\n",
              "      <td>WASHINGTON (Reuters) - Democratic presidential...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>May 26, 2016</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18442</th>\n",
              "      <td>WOW! SENATOR GRASSLEY OUTS Schumer And Schiff…...</td>\n",
              "      <td>A top Republican took to the Senate floor Thur...</td>\n",
              "      <td>left-news</td>\n",
              "      <td>Jun 23, 2017</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16204</th>\n",
              "      <td>Australia's Queensland calls snap election in ...</td>\n",
              "      <td>SYDNEY (Reuters) - Australia s Queensland stat...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>October 29, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13271</th>\n",
              "      <td>British PM's social mobility board quits over ...</td>\n",
              "      <td>LONDON (Reuters) - All four members of the Bri...</td>\n",
              "      <td>worldnews</td>\n",
              "      <td>December 2, 2017</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   title  ... is_true\n",
              "13352  CLINT EASTWOOD Gets Real With The “P*ssy Gener...  ...       0\n",
              "9365   Clinton says she understands U.S. voter concer...  ...       1\n",
              "18442  WOW! SENATOR GRASSLEY OUTS Schumer And Schiff…...  ...       0\n",
              "16204  Australia's Queensland calls snap election in ...  ...       1\n",
              "13271  British PM's social mobility board quits over ...  ...       1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPaxI_CXhhxB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = shuffle(df_data).reset_index(drop=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THz83S-ghhxF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = df_data['title']\n",
        "y = df_data['is_true']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRj9jAFghhxH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_x = text_processing(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpMNDfb0hhxJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQ-9XwBqhhxL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_temp = y_test\n",
        "max_words = 3000\n",
        "tokenize = text.Tokenizer(num_words=max_words)\n",
        "#tokenize.fit_on_texts(x_train) # only fit on train\n",
        "x_train = tokenize.texts_to_sequences(x_train)\n",
        "x_test = tokenize.texts_to_sequences(x_test)\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(y_train)\n",
        "y_train = encoder.transform(y_train)\n",
        "y_test = encoder.transform(y_test)\n",
        "num_classes = np.max(y_train) + 1\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF1LhgwbhhxQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_sequences= 300\n",
        "x_train=pad_sequences(x_train,maxlen=max_sequences)\n",
        "x_test=pad_sequences(x_test,maxlen=max_sequences)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M24HA4czhhxV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#LSTM DTS\n",
        "embed_size = 128\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(max_words,embed_size,input_length=max_sequences))\n",
        "model.add(Bidirectional((LSTM(64,return_sequences = True,recurrent_dropout=0.5))))\n",
        "model.add(Dropout(0.6))\n",
        "model.add(BatchNormalization())\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(48, activation=\"relu\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(len(y.unique()), activation=\"softmax\"))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6HffHBxhhxa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "epochs = 10\n",
        "\n",
        "#callbacks = [EarlyStopping(monitor='val_loss', patience=4, verbose=1),]\n",
        "    \n",
        "history3 =model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs,\n",
        "          validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rrc4MA9hhxh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accr1 = model.evaluate(x_test,y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_-R6LL4hhxl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('AKURASI DARI LSTM \\nTest set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr1[0],accr1[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3JwvvG2hhxn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}